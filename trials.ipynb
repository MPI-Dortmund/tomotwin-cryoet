{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tomotwin.modules.networks.torchmodel import TorchModel\n",
    "\n",
    "class AutoEncoder(TorchModel):\n",
    "\n",
    "    NORM_BATCHNORM = \"BatchNorm\"\n",
    "    NORM_GROUPNORM = \"GroupNorm\"\n",
    "\n",
    "    class Model(nn.Module):\n",
    "        def make_norm(self, norm: Dict, num_channels: int) -> nn.Module:\n",
    "            if norm[\"module\"] == nn.BatchNorm3d:\n",
    "                norm[\"kwargs\"][\"num_features\"] = num_channels\n",
    "                return norm[\"module\"](**norm[\"kwargs\"])\n",
    "            elif norm[\"module\"] == nn.GroupNorm:\n",
    "                norm[\"kwargs\"][\"num_channels\"] = num_channels\n",
    "                return norm[\"module\"](**norm[\"kwargs\"])\n",
    "            else:\n",
    "                raise ValueError(\"Not supported norm\", norm[\"module\"])\n",
    "\n",
    "\n",
    "        def __init__(\n",
    "            self,\n",
    "            output_channels: int,\n",
    "            norm: Dict,\n",
    "            dropout: float = 0.5,\n",
    "            repeat_layers=0,\n",
    "            gem_pooling = None,\n",
    "        ):\n",
    "            super().__init__()\n",
    "            norm_func = self.make_norm(norm, 64)\n",
    "            self.en_layer0 = self._make_conv_layer(1, 64, norm=norm_func)\n",
    "\n",
    "            norm_func = self.make_norm(norm, 128)\n",
    "            self.en_layer1 = self._make_conv_layer(64, 128, norm=norm_func)\n",
    "\n",
    "            norm_func = self.make_norm(norm, 256)\n",
    "            self.en_layer2 = self._make_conv_layer(128, 256, norm=norm_func)\n",
    "\n",
    "            norm_func = self.make_norm(norm, 512)\n",
    "            self.en_layer3 = self._make_conv_layer(256, 512, norm=norm_func)\n",
    "\n",
    "\n",
    "            self.max_pooling = nn.MaxPool3d((2, 2, 2))\n",
    "            if gem_pooling:\n",
    "                self.adap_max_pool = gem_pooling\n",
    "            else:\n",
    "                self.adap_max_pool = nn.AdaptiveAvgPool3d((2, 2, 2))\n",
    "            \n",
    "            self.headnet = self._make_headnet(\n",
    "                 512, 256, 64, 1, dropout=dropout\n",
    "            )\n",
    "\n",
    "            norm_func = self.make_norm(norm, 256)\n",
    "            self.de_layer0 = self._make_deconv_layer(512, 256, norm=norm_func)\n",
    "\n",
    "            norm_func = self.make_norm(norm, 128)\n",
    "            self.de_layer1 = self._make_deconv_layer(256, 128, norm=norm_func)\n",
    "\n",
    "            norm_func = self.make_norm(norm, 64)\n",
    "            self.de_layer2 = self._make_deconv_layer(128, 64, norm=norm_func)\n",
    "\n",
    "            #norm_func = self.make_norm(norm, 64)\n",
    "            #self.de_layer3 = self._make_conv_layer(128, 64, norm=norm_func)\n",
    "\n",
    "            #norm_func = self.make_norm(norm, 1)\n",
    "            #self.de_layer4 = self._make_conv_layer(64, 1, norm=norm_func)\n",
    "            self.de_layer4 = nn.Sequential(\n",
    "                nn.ConvTranspose3d(64, 1, kernel_size=3, padding=1),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.ConvTranspose3d(1, 1, kernel_size=3, padding=1),\n",
    "                nn.Identity() \n",
    "            )\n",
    "\n",
    "            self.up_sampling = nn.Upsample(scale_factor =2)\n",
    "\n",
    "        @staticmethod\n",
    "        def _make_conv_layer(in_c: int, out_c: int, norm: nn.Module, padding: int = 1, kernel_size: int =3):\n",
    "            conv_layer = nn.Sequential(\n",
    "                nn.Conv3d(in_c, out_c, kernel_size=3, padding=padding),\n",
    "                norm,\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Conv3d(out_c, out_c, kernel_size=3, padding=padding),\n",
    "                norm,\n",
    "                nn.LeakyReLU(),\n",
    "            )\n",
    "            return conv_layer\n",
    "        \n",
    "        @staticmethod\n",
    "        def _make_deconv_layer(in_c: int, out_c: int, norm: nn.Module, padding: int = 1, kernel_size: int =3):\n",
    "            conv_layer = nn.Sequential(\n",
    "                nn.ConvTranspose3d(in_c, out_c, kernel_size=3, padding=padding),\n",
    "                norm,\n",
    "                nn.LeakyReLU(),\n",
    "                nn.ConvTranspose3d(out_c, out_c, kernel_size=3, padding=padding),\n",
    "                norm,\n",
    "                nn.LeakyReLU(),\n",
    "            )\n",
    "            return conv_layer\n",
    "\n",
    "        @staticmethod\n",
    "        def _make_headnet(\n",
    "            in_c1: int, in_c2: int,out_c1: int, out_head: int, dropout: float\n",
    "        ) -> nn.Sequential:\n",
    "            headnet = nn.Sequential(\n",
    "                nn.Dropout(p=dropout),\n",
    "                nn.Conv3d(in_c1, in_c2, kernel_size=3, padding=1),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Conv3d(in_c2, out_c1, kernel_size=3, padding=1),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Conv3d(out_c1, out_head, kernel_size=3, padding=1),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.ConvTranspose3d(out_head, out_c1, kernel_size=3, padding=1),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.ConvTranspose3d(out_c1, in_c2, kernel_size=3, padding=1),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.ConvTranspose3d(in_c2,in_c1, kernel_size=3, padding=1),\n",
    "                nn.LeakyReLU(),\n",
    "\n",
    "\n",
    "            )\n",
    "            return headnet\n",
    "\n",
    "        def forward(self, inputtensor):\n",
    "            \"\"\"\n",
    "            Forward pass through the network\n",
    "            :param inputtensor: Input tensor\n",
    "            \"\"\"\n",
    "            inputtensor = F.pad(inputtensor, (1, 2, 1, 2, 1, 2))\n",
    "\n",
    "            out = self.en_layer0(inputtensor)\n",
    "            out = self.max_pooling(out)\n",
    "            out = self.en_layer1(out)\n",
    "            out = self.max_pooling(out)\n",
    "            out = self.en_layer2(out)\n",
    "            out = self.max_pooling(out)\n",
    "            out = self.en_layer3(out)\n",
    "            #out = self.max_pooling(out)\n",
    "\n",
    "            #out = self.en_layer4(out)\n",
    "            #out = self.adap_max_pool(out)\n",
    "            #out = out.reshape(out.size(0), -1)  # flatten\n",
    "            out = self.headnet(out)\n",
    "            #out = out.reshape(-1,512,5,5,5)\n",
    "            out = self.de_layer0(out)\n",
    "            out = self.up_sampling(out)\n",
    "            out = self.de_layer1(out)\n",
    "            out = self.up_sampling(out)\n",
    "            out = self.de_layer2(out)\n",
    "            out = self.up_sampling(out)\n",
    "            #out = self.de_layer3(out)\n",
    "            #out = self.up_sampling(out)\n",
    "            out = self.de_layer4(out)\n",
    "            #out = F.normalize(out, p=2, dim=1)\n",
    "\n",
    "            return out\n",
    "\n",
    "    \"\"\"\n",
    "    Custom 3D convnet, nothing fancy\n",
    "    \"\"\"\n",
    "\n",
    "    def setup_norm(self, norm_name : str, norm_kwargs: dict) -> Dict:\n",
    "        norm = {}\n",
    "        if norm_name == AutoEncoder.NORM_BATCHNORM:\n",
    "            norm[\"module\"] = nn.BatchNorm3d\n",
    "        if norm_name == AutoEncoder.NORM_GROUPNORM:\n",
    "            norm[\"module\"] = nn.GroupNorm\n",
    "        norm[\"kwargs\"] = norm_kwargs\n",
    "\n",
    "        return norm\n",
    "\n",
    "\n",
    "    def setup_gem_pooling(self,gem_pooling_p : float) -> Union[None, nn.Module]:\n",
    "        gem_pooling = None\n",
    "        if gem_pooling_p > 0:\n",
    "            from tomotwin.modules.networks.GeneralizedMeanPooling import GeneralizedMeanPooling\n",
    "            gem_pooling = GeneralizedMeanPooling(norm=gem_pooling_p, output_size=(2, 2, 2))\n",
    "        return gem_pooling\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        norm_name: str,\n",
    "        norm_kwargs: Dict = {},\n",
    "        output_channels: int = 128,\n",
    "        dropout: float = 0.5,\n",
    "        gem_pooling_p: float = 0,\n",
    "        repeat_layers=0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        norm = self.setup_norm(norm_name, norm_kwargs)\n",
    "        gem_pooling = self.setup_gem_pooling(gem_pooling_p)\n",
    "\n",
    "\n",
    "        self.model = self.Model(\n",
    "            output_channels=output_channels,\n",
    "            dropout=dropout,\n",
    "            repeat_layers=repeat_layers,\n",
    "            norm=norm,\n",
    "            gem_pooling=gem_pooling\n",
    "        )\n",
    "\n",
    "    def init_weights(self):\n",
    "        def _init_weights(model):\n",
    "            if isinstance(model, nn.Conv3d):\n",
    "                torch.nn.init.kaiming_normal_(model.weight)\n",
    "\n",
    "        self.model.apply(_init_weights)\n",
    "\n",
    "    def get_model(self) -> nn.Module:\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tomotwin.modules.networks.torchmodel import TorchModel\n",
    "\n",
    "class AutoEncoder(TorchModel):\n",
    "\n",
    "    NORM_BATCHNORM = \"BatchNorm\"\n",
    "    NORM_GROUPNORM = \"GroupNorm\"\n",
    "\n",
    "    class Model(nn.Module):\n",
    "        def make_norm(self, norm: Dict, num_channels: int) -> nn.Module:\n",
    "            if norm[\"module\"] == nn.BatchNorm3d:\n",
    "                norm[\"kwargs\"][\"num_features\"] = num_channels\n",
    "                return norm[\"module\"](**norm[\"kwargs\"])\n",
    "            elif norm[\"module\"] == nn.GroupNorm:\n",
    "                norm[\"kwargs\"][\"num_channels\"] = num_channels\n",
    "                return norm[\"module\"](**norm[\"kwargs\"])\n",
    "            else:\n",
    "                raise ValueError(\"Not supported norm\", norm[\"module\"])\n",
    "\n",
    "\n",
    "        def __init__(\n",
    "            self,\n",
    "            output_channels: int,\n",
    "            norm: Dict,\n",
    "            dropout: float = 0.5,\n",
    "            repeat_layers=0,\n",
    "            gem_pooling = None,\n",
    "        ):\n",
    "            super().__init__()\n",
    "            norm_func = self.make_norm(norm, 64)\n",
    "            self.en_layer0 = self._make_conv_layer(1, 64, norm=norm_func)\n",
    "\n",
    "            norm_func = self.make_norm(norm, 128)\n",
    "            self.en_layer1 = self._make_conv_layer(64, 128, norm=norm_func)\n",
    "\n",
    "            norm_func = self.make_norm(norm, 256)\n",
    "            self.en_layer2 = self._make_conv_layer(128, 256, norm=norm_func)\n",
    "\n",
    "            norm_func = self.make_norm(norm, 512)\n",
    "            self.en_layer3 = self._make_conv_layer(256, 512, norm=norm_func)\n",
    "\n",
    "            norm_func = self.make_norm(norm, 1024)\n",
    "            self.en_layer4 = self._make_conv_layer(512, 1024, norm=norm_func)\n",
    "\n",
    "            self.max_pooling = nn.MaxPool3d((2, 2, 2))\n",
    "            if gem_pooling:\n",
    "                self.adap_max_pool = gem_pooling\n",
    "            else:\n",
    "                self.adap_max_pool = nn.AdaptiveAvgPool3d((2, 2, 2))\n",
    "            \n",
    "            self.headnet = self._make_headnet(\n",
    "                2 * 2 * 2 * 1024, 2048, output_channels, dropout=dropout\n",
    "            )\n",
    "\n",
    "            norm_func = self.make_norm(norm, 512)\n",
    "            self.de_layer0 = self._make_conv_layer(1024, 512, norm=norm_func)\n",
    "\n",
    "            norm_func = self.make_norm(norm, 256)\n",
    "            self.de_layer1 = self._make_conv_layer(512, 256, norm=norm_func)\n",
    "\n",
    "            norm_func = self.make_norm(norm, 128)\n",
    "            self.de_layer2 = self._make_conv_layer(256, 128, norm=norm_func)\n",
    "\n",
    "            norm_func = self.make_norm(norm, 64)\n",
    "            self.de_layer3 = self._make_conv_layer(128, 64, norm=norm_func)\n",
    "\n",
    "            #norm_func = self.make_norm(norm, 1)\n",
    "            #self.de_layer4 = self._make_conv_layer(64, 1, norm=norm_func)\n",
    "            self.de_layer4 = nn.Sequential(\n",
    "                nn.Conv3d(64, 1, kernel_size=3, padding=1),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Conv3d(1, 1, kernel_size=3, padding=1),\n",
    "                nn.LeakyReLU(),\n",
    "            )\n",
    "\n",
    "            self.up_sampling = nn.Upsample(scale_factor =2)\n",
    "\n",
    "        @staticmethod\n",
    "        def _make_conv_layer(in_c: int, out_c: int, norm: nn.Module, padding: int = 1, kernel_size: int =3):\n",
    "            conv_layer = nn.Sequential(\n",
    "                nn.Conv3d(in_c, out_c, kernel_size=kernel_size, padding=padding),\n",
    "                norm,\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Conv3d(out_c, out_c, kernel_size=kernel_size, padding=padding),\n",
    "                norm,\n",
    "                nn.LeakyReLU(),\n",
    "            )\n",
    "            return conv_layer\n",
    "\n",
    "        @staticmethod\n",
    "        def _make_headnet(\n",
    "            in_c1: int, out_c1: int, out_head: int, dropout: float\n",
    "        ) -> nn.Sequential:\n",
    "            headnet = nn.Sequential(\n",
    "                nn.Dropout(p=dropout),\n",
    "                nn.Linear(in_c1, out_c1),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(out_c1, out_c1),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(out_c1, out_head),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(out_head,out_c1),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(out_c1,in_c1)\n",
    "            )\n",
    "            return headnet\n",
    "\n",
    "        def forward(self, inputtensor):\n",
    "            \"\"\"\n",
    "            Forward pass through the network\n",
    "            :param inputtensor: Input tensor\n",
    "            \"\"\"\n",
    "            #inputtensor = F.pad(inputtensor, (1, 2, 1, 2, 1, 2))\n",
    "\n",
    "            out = self.en_layer0(inputtensor)\n",
    "            out = self.max_pooling(out)\n",
    "            out = self.en_layer1(out)\n",
    "            out = self.max_pooling(out)\n",
    "            out = self.en_layer2(out)\n",
    "            out = self.max_pooling(out)\n",
    "            out = self.en_layer3(out)\n",
    "            out = self.max_pooling(out)\n",
    "            out = self.en_layer4(out)\n",
    "            #out = self.adap_max_pool(out)\n",
    "            out = out.reshape(out.size(0), -1) \n",
    "            out = self.headnet(out)\n",
    "            out = out.reshape(-1,1024,2,2,2)\n",
    "            out = self.de_layer0(out)\n",
    "            out = self.up_sampling(out)\n",
    "            out = self.de_layer1(out)\n",
    "            out = self.up_sampling(out)\n",
    "            out = self.de_layer2(out)\n",
    "            out = self.up_sampling(out)\n",
    "            out = self.de_layer3(out)\n",
    "            out = self.up_sampling(out)\n",
    "            out = self.de_layer4(out)\n",
    "            #out = F.normalize(out, p=2, dim=1)\n",
    "\n",
    "            return out\n",
    "\n",
    "    \"\"\"\n",
    "    Custom 3D convnet, nothing fancy\n",
    "    \"\"\"\n",
    "\n",
    "    def setup_norm(self, norm_name : str, norm_kwargs: dict) -> Dict:\n",
    "        norm = {}\n",
    "        if norm_name == AutoEncoder.NORM_BATCHNORM:\n",
    "            norm[\"module\"] = nn.BatchNorm3d\n",
    "        if norm_name == AutoEncoder.NORM_GROUPNORM:\n",
    "            norm[\"module\"] = nn.GroupNorm\n",
    "        norm[\"kwargs\"] = norm_kwargs\n",
    "\n",
    "        return norm\n",
    "\n",
    "\n",
    "    def setup_gem_pooling(self,gem_pooling_p : float) -> Union[None, nn.Module]:\n",
    "        gem_pooling = None\n",
    "        if gem_pooling_p > 0:\n",
    "            from tomotwin.modules.networks.GeneralizedMeanPooling import GeneralizedMeanPooling\n",
    "            gem_pooling = GeneralizedMeanPooling(norm=gem_pooling_p, output_size=(2, 2, 2))\n",
    "        return gem_pooling\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        norm_name: str,\n",
    "        norm_kwargs: Dict = {},\n",
    "        output_channels: int = 128,\n",
    "        dropout: float = 0.5,\n",
    "        gem_pooling_p: float = 0,\n",
    "        repeat_layers=0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        norm = self.setup_norm(norm_name, norm_kwargs)\n",
    "        gem_pooling = self.setup_gem_pooling(gem_pooling_p)\n",
    "\n",
    "\n",
    "        self.model = self.Model(\n",
    "            output_channels=output_channels,\n",
    "            dropout=dropout,\n",
    "            repeat_layers=repeat_layers,\n",
    "            norm=norm,\n",
    "            gem_pooling=gem_pooling\n",
    "        )\n",
    "\n",
    "    def init_weights(self):\n",
    "        def _init_weights(model):\n",
    "            if isinstance(model, nn.Conv3d):\n",
    "                torch.nn.init.kaiming_normal_(model.weight)\n",
    "\n",
    "        self.model.apply(_init_weights)\n",
    "\n",
    "    def get_model(self) -> nn.Module:\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_name = \"GroupNorm\"\n",
    "norm_kwargs = {\"num_groups\": 64,\n",
    "        \"num_channels\": 1024}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = AutoEncoder(norm_name,norm_kwargs,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = M.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 64, 40, 40, 40])\n",
      "torch.Size([12, 128, 10, 10, 10])\n",
      "torch.Size([12, 512, 5, 5, 5])\n",
      "torch.Size([12, 512, 5, 5, 5])\n",
      "torch.Size([12, 256, 10, 10, 10])\n",
      "torch.Size([12, 128, 20, 20, 20])\n",
      "torch.Size([12, 64, 20, 20, 20])\n",
      "torch.Size([12, 64, 40, 40, 40])\n",
      "torch.Size([12, 1, 40, 40, 40])\n"
     ]
    }
   ],
   "source": [
    "out = Model(torch.rand(12,1,37,37,37))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 1, 40, 40, 40])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomotwin.modules.training.mrctriplethandler import MRCTripletHandler\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class MRCVolumeDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.file_paths = self._get_file_paths()\n",
    "        self.reader = MRCTripletHandler()\n",
    "\n",
    "    def _get_file_paths(self):\n",
    "        file_paths = []\n",
    "        for round_dir in os.listdir(self.root_dir):\n",
    "            round_path = os.path.join(self.root_dir, round_dir)\n",
    "            if os.path.isdir(round_path):\n",
    "                for tomo_dir in os.listdir(round_path):\n",
    "                    tomo_path = os.path.join(round_path, tomo_dir)\n",
    "                    if os.path.isdir(tomo_path):\n",
    "                        mrc_files = [f for f in os.listdir(tomo_path) if f.endswith('.mrc')]\n",
    "                        for mrc_file in mrc_files:\n",
    "                            file_paths.append(os.path.join(tomo_path, mrc_file))\n",
    "        return file_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mrc_path = self.file_paths[idx]\n",
    "        volume = self.reader.read_mrc_and_norm(mrc_path)\n",
    "\n",
    "        return {'input': volume, 'target': volume}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "root_dir = '/home/yousef.metwally/projects/data/tomotwin_training_data/validation'\n",
    "\n",
    "dataset = MRCVolumeDataset(root_dir)\n",
    "batch_size = 32\n",
    "shuffle = True  \n",
    "num_workers = 4  \n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def loss_function(recon_x, x):\n",
    "    mse_loss = F.mse_loss(recon_x, x)\n",
    "    return mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def train_autoencoder(model, data_loader, optimizer, num_epochs=10, device='cuda'):\n",
    "    writer = SummaryWriter('/home/yousef.metwally/projects/AutoEncoder')\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        with tqdm(data_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as progress_bar:\n",
    "            for batch_idx, data in enumerate(progress_bar):\n",
    "                input_data = data['input'].to(device)\n",
    "                #if batch_idx > 500:\n",
    "                 #   print(input_data.shape)\n",
    "                input_data = input_data.reshape(-1,1,37,37,37)\n",
    "                target_data = data['target'].to(device)\n",
    "                target_data = F.pad(target_data, (1, 2, 1, 2, 1, 2))\n",
    "                target_data = target_data.reshape(-1,1,40,40,40)\n",
    "                optimizer.zero_grad()\n",
    "                recon_data = model(input_data)\n",
    "                loss = loss_function(recon_data, target_data)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                avg_loss = total_loss / (batch_idx + 1)\n",
    "                writer.add_scalar('Loss/train', avg_loss, epoch * len(data_loader) + batch_idx)\n",
    "\n",
    "                \n",
    "                progress_bar.set_postfix(loss=avg_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Avg. Loss: {avg_loss:.4f}\")\n",
    "        torch.save(model.state_dict(), f\"/home/yousef.metwally/projects/AutoEncoder/weights/run1/model_weights_epoch_{epoch+1}.pt\")\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2\"\n",
    "num_epochs = 200\n",
    "M = AutoEncoder(norm_name,norm_kwargs,32)\n",
    "model = M.get_model()\n",
    "model = nn.DataParallel(model)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_autoencoder(model, data_loader, optimizer, num_epochs, device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.file_paths = self._get_file_paths()\n",
    "        self.reader = MRCTripletHandler()\n",
    "\n",
    "    def _get_file_paths(self):\n",
    "        file_paths = [os.path.join(self.root_dir, f) for f in os.listdir(self.root_dir) if f.endswith('.mrc')]\n",
    "        return file_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mrc_path = self.file_paths[idx]\n",
    "        volume = self.reader.read_mrc_and_norm(mrc_path)\n",
    "        return {'input': volume, 'target': volume}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '/home/yousef.metwally/projects/data/tomotwin_training_data/test'\n",
    "test_dataset = testDataset(test_dir)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "model = UNet3D(1,1)\n",
    "model = nn.DataParallel(model)\n",
    "checkpoint_path = '/home/yousef.metwally/projects/UNet/weights/model_weights_epoch_16.pt'\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint)\n",
    "device = 'cuda'\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 2/2 [00:01<00:00,  1.20batch/s, loss=1.49e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 5.2851032178912064e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate (model, data_loader):\n",
    "    total_loss = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        with tqdm(data_loader, desc=\"Evaluating\", unit=\"batch\") as progress_bar:\n",
    "            for batch_idx, data in enumerate(progress_bar):\n",
    "                input_data = data['input'].to(device)\n",
    "                input_data = input_data.reshape(-1, 1, 37, 37, 37)\n",
    "                target_data = data['target'].to(device)\n",
    "                target_data = target_data.reshape(-1, 1, 37, 37, 37)\n",
    "                recon_data = model(input_data)\n",
    "                loss = loss_function(recon_data, target_data)\n",
    "                total_loss += loss.item()\n",
    "                progress_bar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    print(f\"Validation Loss: {avg_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data_loader):\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_data = batch['input'].unsqueeze(1)\n",
    "            target_data = batch['target'].unsqueeze(1)\n",
    "            output = model(input_data)\n",
    "            predictions.append(output.squeeze(1).cpu().numpy())\n",
    "            targets.append(target_data.squeeze(1).cpu().numpy())\n",
    "    return predictions, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mrcfile\n",
    "def save_as_mrc(data, filename):\n",
    "    with mrcfile.new(filename, overwrite=True) as mrc:\n",
    "        mrc.set_data(data.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, targets = predict(model, test_loader)\n",
    "save_dir = '/home/yousef.metwally/projects/UNet/output'\n",
    "def save_ouput (out_dir: str, predictions, targets):\n",
    "    for i, (pred, target) in enumerate(zip(predictions, targets)):\n",
    "        pred_filename = os.path.join(out_dir, f'prediction_{i:03d}.mrc')\n",
    "        target_filename = os.path.join(out_dir, f'target_{i:03d}.mrc')\n",
    "        save_as_mrc(pred, pred_filename)\n",
    "        save_as_mrc(target, target_filename)\n",
    "        print(f'Saved prediction to {pred_filename} and target to {target_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "TensorBoard 2.16.2 at http://gtxr3.srv-local.mpi-dortmund.mpg.de:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir='/home/yousef.metwally/projects/UNet/' --bind_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Model:\n\tsize mismatch for de_layer0.0.weight: copying a param with shape torch.Size([512, 256, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 3, 3, 3]).\n\tsize mismatch for de_layer1.0.weight: copying a param with shape torch.Size([256, 128, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 3, 3, 3]).\n\tsize mismatch for de_layer2.0.weight: copying a param with shape torch.Size([128, 64, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 128, 3, 3, 3]).\n\tsize mismatch for de_layer4.0.weight: copying a param with shape torch.Size([64, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([1, 64, 3, 3, 3]).\n\tsize mismatch for de_layer4.2.weight: copying a param with shape torch.Size([1, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([1, 1, 1, 1, 1]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(checkpoint_path)\n\u001b[1;32m      8\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m {k\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodule.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m): v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m checkpoint\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tomotwin/lib/python3.10/site-packages/torch/nn/modules/module.py:2189\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2184\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2185\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2186\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2190\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Model:\n\tsize mismatch for de_layer0.0.weight: copying a param with shape torch.Size([512, 256, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 3, 3, 3]).\n\tsize mismatch for de_layer1.0.weight: copying a param with shape torch.Size([256, 128, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 3, 3, 3]).\n\tsize mismatch for de_layer2.0.weight: copying a param with shape torch.Size([128, 64, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 128, 3, 3, 3]).\n\tsize mismatch for de_layer4.0.weight: copying a param with shape torch.Size([64, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([1, 64, 3, 3, 3]).\n\tsize mismatch for de_layer4.2.weight: copying a param with shape torch.Size([1, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([1, 1, 1, 1, 1])."
     ]
    }
   ],
   "source": [
    "reader = MRCTripletHandler()\n",
    "v_path = '/home/yousef.metwally/projects/data/tomotwin_training_data/test/round01_t08_0XXX_000.mrc'\n",
    "volume = reader.read_mrc_and_norm(v_path)\n",
    "M = AutoEncoder(norm_name,norm_kwargs,32)\n",
    "model = M.get_model()\n",
    "checkpoint_path = '/home/yousef.metwally/projects/AutoEncoder/weights/run1/model_weights_epoch_200.pt'\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "state_dict = {k.replace('module.', ''): v for k, v in checkpoint.items()}\n",
    "model.load_state_dict(state_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = os.listdir(\"/home/yousef.metwally/projects/AutoEncoder/weights/run1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_weights_epoch_197.pt',\n",
       " 'model_weights_epoch_198.pt',\n",
       " 'model_weights_epoch_199.pt',\n",
       " 'model_weights_epoch_200.pt']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Down, self).__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool3d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super(Up, self).__init__()\n",
    "\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose3d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # Ensure the shapes match for concatenation\n",
    "        diffZ = x2.size(2) - x1.size(2)\n",
    "        diffY = x2.size(3) - x1.size(3)\n",
    "        diffX = x2.size(4) - x1.size(4)\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2,\n",
    "                        diffZ // 2, diffZ - diffZ // 2])\n",
    "        \n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(UNet3D, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 512)\n",
    "        self.up1 = Up(1024, 256, bilinear)\n",
    "        self.up2 = Up(512, 128, bilinear)\n",
    "        self.up3 = Up(256, 64, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d) or isinstance(m, nn.ConvTranspose3d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from typing import Dict, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tomotwin.modules.networks.torchmodel import TorchModel\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from tomotwin.modules.training.mrctriplethandler import MRCTripletHandler\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Down, self).__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool3d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super(Up, self).__init__()\n",
    "\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose3d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffZ = x2.size(2) - x1.size(2)\n",
    "        diffY = x2.size(3) - x1.size(3)\n",
    "        diffX = x2.size(4) - x1.size(4)\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2,\n",
    "                        diffZ // 2, diffZ - diffZ // 2])\n",
    "        \n",
    "        #x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x1)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, n_channels, out_channels, bilinear=True):\n",
    "        super(UNet3D, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 1024)\n",
    "        self.down5 = Down(1024,1024)\n",
    "        self.up1 = Up(1024, 512, bilinear)\n",
    "        self.up2 = Up(512, 256, bilinear)\n",
    "        self.up3 = Up(256, 128, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.up5 = Up(64,64)\n",
    "        self.outc = OutConv(64, out_channels)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x6 = self.down5(x5)\n",
    "        x = self.up1(x6, x5)\n",
    "        x = self.up2(x, x4)\n",
    "        x = self.up3(x, x3)\n",
    "        x = self.up4(x, x2)\n",
    "        x = self.up5(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "    \n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d) or isinstance(m, nn.ConvTranspose3d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet3D(1,1)\n",
    "out = model(torch.rand(12,1,37,37,37))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tomotwin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
